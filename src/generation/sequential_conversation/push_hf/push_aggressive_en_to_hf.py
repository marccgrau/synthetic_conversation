#!/usr/bin/env python3
import glob
import json
import os

from dotenv import load_dotenv
from huggingface_hub import create_repo, upload_file

load_dotenv()


def combine_json_files(input_directory: str, output_file: str) -> None:
    """
    Reads all JSON files from input_directory (aggressive conversations folder),
    combines them, and writes to output_file in JSON Lines (JSONL) format.
    """
    combined_conversations = []
    json_files = glob.glob(os.path.join(input_directory, "*.json"))
    print(f"Found {len(json_files)} JSON files in {input_directory}.")

    for filepath in json_files:
        with open(filepath, "r", encoding="utf-8") as f:
            try:
                data = json.load(f)
                if isinstance(data, list):
                    combined_conversations.extend(data)
                else:
                    print(f"Skipping {filepath}: Not a list of records.")
            except Exception as e:
                print(f"Error reading {filepath}: {e}")

    # Write each conversation record as a single JSON line
    with open(output_file, "w", encoding="utf-8") as f:
        for record in combined_conversations:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    print(f"Combined {len(combined_conversations)} records into {output_file}.")


def push_to_huggingface(repo_name: str, file_path: str, token: str) -> None:
    """
    Creates a dataset repository (if it doesn't exist) and uploads the file to it.
    """
    try:
        create_repo(repo_name, repo_type="dataset", exist_ok=True, token=token)
        print(f"Repository '{repo_name}' is ready.")
    except Exception as e:
        print(f"Error creating repo: {e}")

    try:
        upload_file(
            path_or_fileobj=file_path,
            path_in_repo=os.path.basename(file_path),
            repo_id=repo_name,
            repo_type="dataset",
            token=token,
        )
        print(f"Uploaded '{file_path}' to repository '{repo_name}'.")
    except Exception as e:
        print(f"Error uploading {file_path}: {e}")


def main():
    # Define the directory containing aggressive conversations
    input_directory = "../agentic_simulation_outputs/aggressive_en"
    output_file = "../aggressive_en_conversations_dataset.jsonl"

    # Combine all JSON files into a single JSONL file
    combine_json_files(input_directory, output_file)

    # Retrieve your Hugging Face token from environment variables
    hf_token = os.environ.get("HF_TOKEN")
    if not hf_token:
        raise ValueError(
            "Please set the HF_TOKEN environment variable with your Hugging Face API token."
        )

    # Define the Hugging Face repository name
    repo_name = "marccgrau/agentic_synthetic_aggressive_conversations_en"

    # Create a dataset card as a README file including metadata and guidance.
    readme_content = """---
license: "apache-2.0"
pretty_name: "Simulated Aggressive Customer Service Conversations"
language: "en"
task_categories:
  - text-generation
  - summarization
size_categories: ["unknown"]
tags:
  - simulation
  - synthetic
  - customer_service
  - aggressive_interactions
multilinguality: monolingual
language_creators:
  - synthetic
---

# Simulated Aggressive Customer Service Conversations Dataset

## Overview
This dataset contains **aggressive** customer service conversations generated by an agentic simulation system.
Each record is stored in JSON Lines (JSONL) format and includes:
- **Scenario Metadata:** Selected bank, customer, agent profiles, and task details.
- **Conversation Messages:** Full message history between the customer and service agent.
- **Summary:** A German summary of the conversation.
- **Cost Metrics:** API cost tracking for the conversation simulation.

## Intended Use
The dataset is designed for:
- Training AI models to handle **aggressive customer interactions** in financial services.
- Studying **customer frustration and escalation patterns** in banking and insurance.
- Developing improved **de-escalation detection** in customer service AI.

## Potential Biases and Limitations
- Conversations are synthetically generated and may exhibit biases from predefined scenarios.
- Aggressiveness is simulated and might not fully reflect real-world customer behavior.
- The dataset does not include **real customer interactions**â€”it is meant for simulation-based research.

## Additional Information
For more details on the dataset creation process, reach out to the dataset maintainers.
"""
    readme_file = "README.md"
    with open(readme_file, "w", encoding="utf-8") as f:
        f.write(readme_content)
    print(f"Created dataset card and README file '{readme_file}' with metadata.")

    # Push the combined dataset file and README to Hugging Face
    push_to_huggingface(repo_name, output_file, hf_token)
    push_to_huggingface(repo_name, readme_file, hf_token)


if __name__ == "__main__":
    main()
